{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Top1wCkMFu6C"
      },
      "source": [
        "# 使用 ESC-50 微调 MiDashengLM\n",
        "\n",
        "## 运行前检查\n",
        "\n",
        "在运行之前，请确保 MDL-Toolkit 已正确安装。运行下面的命令，应该输出`mdl-toolkit`的帮助信息。如果命令运行不正确，请检查你的安装。有关更多信息，请参考[安装指南](../docs_zh/installation.md)。\n",
        "\n",
        "> ### 注意\n",
        "> 在本地运行时，强烈建议将 MDL-Toolkit 安装到独立的虚拟环境中，以避免依赖项问题。由于 Notebook 中处理虚拟环境较复杂，可以将 MDL-Toolkit 直接安装到 Notebook 所在虚拟环境。\n",
        "\n",
        "> ### 注意\n",
        "> 在示例代码执行过程中，将通过网络下载 ESC-50 数据集和 MiDashengLM-7B bf16 精度的完整权重。请确保到 Github 和 Huggingface 的网络连接顺畅，并预留充足存储空间。\n",
        ">\n",
        "> 也可以配置 MDL-Toolkit 以从 Modelscope 下载模型。要使用 Modelscope，请确保安装时启用了`modelscope`可选功能，并在`mdl-toolkit`命令中添加`--from-modelscope true`选项。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OWfIBxnmFwft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d987343f-7d64-4aeb-bd0c-cf5c30a2addb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: mdl-toolkit [-h] {train,convert-dataset,inference} ...\r\n",
            "\r\n",
            "options:\r\n",
            "  -h, --help            show this help message and exit\r\n",
            "\r\n",
            "subcommands:\r\n",
            "  {train,convert-dataset,inference}\r\n",
            "    train\r\n",
            "    convert-dataset\r\n",
            "    inference\r\n"
          ]
        }
      ],
      "source": [
        "# 安装 MDL-Toolkit，例如：\n",
        "# !pip install mdl-toolkit\n",
        "!mdl-toolkit --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWHSmQX9GLRl"
      },
      "source": [
        "## 数据准备\n",
        "\n",
        "### 下载 ESC-50 数据集并解压缩\n",
        "\n",
        "运行下面的命令将下载数据集并解压缩。你也可以通过其他方式获取数据集文件，此时后续步骤中的路径需要相应调整。\n",
        "\n",
        "> ### 网络访问\n",
        "> 运行该命令将从 Github 下载数据集文件（约 615MiB），可能需要一些时间。请确保网络状况良好，存储空间充足，并耐心等待。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KB3C95O3GMBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c8c908-0c73-4cfc-8262-e5e00f5306af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘ESC-50.zip’ already there; not retrieving.\r\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://github.com/karoldvl/ESC-50/archive/master.zip -O ESC-50.zip\n",
        "!unzip -o -q ESC-50.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyN8OKDlHwkC"
      },
      "source": [
        "现在，ESC-50 数据集应该在`ESC-50-master`目录中可用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vunzt5yTH2ov"
      },
      "source": [
        "### 将数据集转换为训练所需的格式\n",
        "\n",
        "ESC-50 提供了 CSV 格式的样本列表，其中样本被分为`1`到`5`总共五个`fold`。数据集的前 10 个样本如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q9NsOpJxH5cp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0221435-1b29-4f48-a2cb-e0a011c5a72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename,fold,target,category,esc10,src_file,take\r\n",
            "1-100032-A-0.wav,1,0,dog,True,100032,A\r\n",
            "1-100038-A-14.wav,1,14,chirping_birds,False,100038,A\r\n",
            "1-100210-A-36.wav,1,36,vacuum_cleaner,False,100210,A\r\n",
            "1-100210-B-36.wav,1,36,vacuum_cleaner,False,100210,B\r\n",
            "1-101296-A-19.wav,1,19,thunderstorm,False,101296,A\r\n",
            "1-101296-B-19.wav,1,19,thunderstorm,False,101296,B\r\n",
            "1-101336-A-30.wav,1,30,door_wood_knock,False,101336,A\r\n",
            "1-101404-A-34.wav,1,34,can_opening,False,101404,A\r\n",
            "1-103298-A-9.wav,1,9,crow,False,103298,A\r\n",
            "1-103995-A-30.wav,1,30,door_wood_knock,False,103995,A\r\n"
          ]
        }
      ],
      "source": [
        "!head -n 11 ESC-50-master/meta/esc50.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywvoU4PIOsq"
      },
      "source": [
        "可以使用下面的代码根据`fold`划分训练集和测试集，并格式化数据集以训练模型以格式`category: <category>, target: <target>`预测音频类别。你可以试着调整下面的代码，例如，试着让模型输出 JSON。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YpYPE2jlHxPW"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "esc50_base = Path(\"ESC-50-master\")\n",
        "meta_file = esc50_base / \"meta\" / \"esc50.csv\"\n",
        "train_output = Path(\"train.csv\")\n",
        "test_output = Path(\"test.csv\")\n",
        "\n",
        "with (\n",
        "    open(meta_file, \"r\") as meta,\n",
        "    open(train_output, \"w\") as train,\n",
        "    open(test_output, \"w\") as test,\n",
        "):\n",
        "    reader = csv.DictReader(meta)\n",
        "    train_writer = csv.DictWriter(train, fieldnames=[\"audio\", \"prediction\"])\n",
        "    test_writer = csv.DictWriter(test, fieldnames=[\"audio\", \"prediction\"])\n",
        "    train_writer.writeheader()\n",
        "    test_writer.writeheader()\n",
        "\n",
        "    for row in reader:\n",
        "        writer = train_writer if row[\"fold\"] != \"5\" else test_writer\n",
        "        writer.writerow(\n",
        "            {\n",
        "                \"audio\": os.fspath(esc50_base / \"audio\" / row[\"filename\"]),\n",
        "                \"prediction\": f\"category: {row['category']}, target: {row['target']}\",\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aAuoiS-rIxkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7f219d-829e-467f-ff5e-a4c1913706bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Train split ====\n",
            "audio,prediction\n",
            "ESC-50-master/audio/1-100032-A-0.wav,\"category: dog, target: 0\"\n",
            "ESC-50-master/audio/1-100038-A-14.wav,\"category: chirping_birds, target: 14\"\n",
            "ESC-50-master/audio/1-100210-A-36.wav,\"category: vacuum_cleaner, target: 36\"\n",
            "ESC-50-master/audio/1-100210-B-36.wav,\"category: vacuum_cleaner, target: 36\"\n",
            "ESC-50-master/audio/1-101296-A-19.wav,\"category: thunderstorm, target: 19\"\n",
            "ESC-50-master/audio/1-101296-B-19.wav,\"category: thunderstorm, target: 19\"\n",
            "ESC-50-master/audio/1-101336-A-30.wav,\"category: door_wood_knock, target: 30\"\n",
            "ESC-50-master/audio/1-101404-A-34.wav,\"category: can_opening, target: 34\"\n",
            "ESC-50-master/audio/1-103298-A-9.wav,\"category: crow, target: 9\"\n",
            "ESC-50-master/audio/1-103995-A-30.wav,\"category: door_wood_knock, target: 30\"\n",
            "==== Test split  ====\n",
            "audio,prediction\n",
            "ESC-50-master/audio/5-103415-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103416-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103418-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103420-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103421-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103422-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-117118-A-42.wav,\"category: siren, target: 42\"\n",
            "ESC-50-master/audio/5-117120-A-42.wav,\"category: siren, target: 42\"\n",
            "ESC-50-master/audio/5-117122-A-42.wav,\"category: siren, target: 42\"\n",
            "ESC-50-master/audio/5-117250-A-2.wav,\"category: pig, target: 2\"\n"
          ]
        }
      ],
      "source": [
        "!echo '==== Train split ===='\n",
        "!head -n 11 train.csv\n",
        "!echo '==== Test split  ===='\n",
        "!head -n 11 test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 检查预训练模型效果\n",
        "\n",
        "MiDashengLM 并不了解 ESC-50 的类别信息，因此直接用于推理时会输出不正确的类别。在本教程中，我们将使用微调方式调整模型的输出，使其与预期相符。在实践中，通过精心设计提示词或添加解码约束，可能无需微调亦可改进模型的输出，你可以根据实际情况选择合适的方式。\n",
        "\n",
        "MDL-Toolkit 提供了一个便捷推理命令，可以快速运行推理任务，而无需手动编写推理代码。推理命令的输入与训练时使用的格式相同，但无需包含`prediction`列，推理命令会将推理结果放入`prediction`列，并保留所有其他列的内容。由于推理输入格式与训练输入兼容，可以直接使用上面生成的`test.csv`文件进行推理。我们可以使用推理命令观察未微调模型的输出。\n",
        "\n",
        "参数说明：\n",
        "* `--model-name mispeech/midashenglm-7b-bf16`：要使用的模型的 Huggingface 名称或本地路径。\n",
        "\n",
        "> ### 注意\n",
        "> 本教程使用 bf16 精度模型权重以减少网络和磁盘占用。如果已经拥有 fp32 精度的完整权重，则可以使用`--model-name mispeech/midashenglm-7b`替换`--model-name mispeech/midashenglm-7b-bf16`，以避免重复下载和存储模型权重。"
      ],
      "metadata": {
        "id": "6twsROtkeeb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mdl-toolkit inference \\\n",
        "    test.csv \\\n",
        "    --system-prompt \"Output the predicted category in the format of category: <category>, category_id: <category_id>.\" \\\n",
        "    --output orig-output.csv \\\n",
        "    --model-name mispeech/midashenglm-7b-bf16\n",
        "! head -n 11 orig-output.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncZKkhfGk0Aj",
        "outputId": "1b57ec28-555b-441b-e070-845d59f708f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:04<00:00,  1.01s/it]\n",
            "Generating train split: 400 examples [00:00, 7764.21 examples/s]\n",
            "Processing dataset: 100%|██████████████| 400/400 [00:16<00:00, 23.68 examples/s]\n",
            "Batching examples (num_proc=32): 100%|█| 400/400 [00:02<00:00, 146.58 examples/s\n",
            "Inference: 100%|████████████████████████████████| 32/32 [00:33<00:00,  1.05s/it]\n",
            "audio,prediction\n",
            "ESC-50-master/audio/5-103415-A-2.wav,\"category: livestock, category_id: 1\"\n",
            "ESC-50-master/audio/5-103416-A-2.wav,\"category: music, category_id: 1\"\n",
            "ESC-50-master/audio/5-103418-A-2.wav,\"category: pig, category_id: 1\"\n",
            "ESC-50-master/audio/5-103420-A-2.wav,\"category: animal, category_id: 1\"\n",
            "ESC-50-master/audio/5-103421-A-2.wav,\"category: pig, category_id: 1\"\n",
            "ESC-50-master/audio/5-103422-A-2.wav,\"category: animal, category_id: 1\"\n",
            "ESC-50-master/audio/5-117118-A-42.wav,\"category: alarm, category_id: 1\"\n",
            "ESC-50-master/audio/5-117120-A-42.wav,\"category: alarm, category_id: 1\"\n",
            "ESC-50-master/audio/5-117122-A-42.wav,\"category: alarm, category_id: 1\"\n",
            "ESC-50-master/audio/5-117250-A-2.wav,\"category: animal, category_id: 1\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz_9MBs1JBd7"
      },
      "source": [
        "### 对数据进行转换\n",
        "\n",
        "为了提高训练效率，我们对数据集进行转换以生成用于训练的数据集格式。下面的命令会对 CSV 文件进行转换，并使用一个简单的系统提示词。你也可以跳过该步骤并在训练时进行转换，此时后续步骤中的数据集路径需要替换为对应的 CSV 文件路径，并且每次训练前都需要一定时间进行转换。\n",
        "\n",
        "> ### 网络访问\n",
        "> 运行该命令将从 Huggingface 下载模型分词器。请确保网络状况良好并耐心等待。\n",
        ">\n",
        "> 要从 Modelscope 下载模型，请在命令后添加`--from-modelscope true`选项，并确保安装时启用了`modelscope`可选功能。\n",
        "\n",
        "参数说明：\n",
        "* `train.csv`：输入 CSV 文件的路径。\n",
        "* `--output train-converted/`：输出目录的路径，转换后的数据集将保存在该目录中。将会自动创建该目录并覆盖已经存在的内容。\n",
        "* `--system-prompt ...`：指定一个简单的系统提示词，用于指导模型的行为。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qvxAlVXkI4_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21567075-0cb5-40ea-cf29-3cee033d5e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating train split: 1600 examples [00:00, 29889.39 examples/s]\n",
            "Processing dataset: 100%|████████████| 1600/1600 [00:46<00:00, 34.63 examples/s]\n",
            "Deriving labels for training (num_proc=32): 100%|█| 1600/1600 [00:02<00:00, 705.\n",
            "Saving the dataset (2/2 shards): 100%|█| 1600/1600 [00:02<00:00, 617.50 examples\n",
            "Processing dataset: 100%|██████████████| 400/400 [00:17<00:00, 23.26 examples/s]\n",
            "Deriving labels for training (num_proc=32): 100%|█| 400/400 [00:01<00:00, 211.03\n",
            "Saving the dataset (1/1 shards): 100%|█| 400/400 [00:00<00:00, 1333.25 examples/\n"
          ]
        }
      ],
      "source": [
        "!mdl-toolkit convert-dataset \\\n",
        "    train.csv \\\n",
        "    --output train-converted/ \\\n",
        "    --system-prompt \"Output the predicted category in the format of category: <category>, category_id: <category_id>.\"\n",
        "!mdl-toolkit convert-dataset \\\n",
        "    test.csv \\\n",
        "    --output test-converted/ \\\n",
        "    --system-prompt \"Output the predicted category in the format of category: <category>, category_id: <category_id>.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdazC9j9LRD9"
      },
      "source": [
        "## 训练模型\n",
        "\n",
        "我们希望模型在对音频进行分类的同时，能够遵循我们指定的格式输出结果。由于调整格式较为简单，我们将 LoRA rank 设置为 16。由于样本数较少，我们设定每隔 50 步进行一次评估。由于完整模型权重较大，我们使用`bitsandbytes` 4bit 量化版本以减少网络传输和显存占用。该命令将自动使用检测到的加速器加速训练过程，无需手动干预。\n",
        "\n",
        "> ### 网络访问\n",
        "> 运行该命令将从 Huggingface 下载模型权重，可能需要一些时间。请确保网络状况良好，存储空间充足，并耐心等待。\n",
        ">\n",
        "> 要从 Modelscope 下载模型，请在命令后添加`--from-modelscope true`选项，并确保安装时启用了`modelscope`可选功能。\n",
        "\n",
        "> ### 注意\n",
        "> 建议使用高性能 GPU 进行训练，以加快训练速度，MDL-Toolkit 将自动检测并使用可用的 GPU。默认情况下，训练过程将使用单个 GPU。如果你有多张 GPU，请参考[分布式训练指南](../docs_zh/distributed.md)。不要仅使用 CPU 进行训练，否则训练过程会非常缓慢。\n",
        ">\n",
        "> 要使用 bf16 精度运行训练，需要约 18GiB 显存，如果显存不足，可以尝试添加`--quantization 8bit`或`--quantization 4bit`，在加载时使用 bitsandbytes 将模型权重量化为8位或4位。注意，量化可能会降低模型的能力，导致次优的输出结果。\n",
        "\n",
        "参数说明：\n",
        "* `--lora-rank 32`：设置 LoRA 的 rank 为 32。对于更复杂的任务，可以尝试增加 rank 以提高模型的表达能力。\n",
        "* `--eval-steps 100`：每隔 100 步进行一次评估。\n",
        "* `--train-dataset train-converted/`：指定训练数据集的路径。也可以直接指定 CSV 文件的路径，将在训练前完成转换。\n",
        "* `--eval-dataset test-converted/`：指定评估数据集的路径。可以直接指定 CSV 文件的路径。如果未指定，将不会进行评估。\n",
        "* `--output output/`：指定输出目录的路径。训练过程中的检查点和训练结果将保存在该目录中。将会自动创建该目录并覆盖已经存在的内容。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sHZXuZrwLR_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbd7728-62af-452d-ab24-c6b4c6608540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distributed: NO\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:03<00:00,  1.04it/s]\n",
            "Model loaded with torch.bfloat16\n",
            "trainable params: 68,968,448 || all params: 8,350,708,352 || trainable%: 0.8259\n",
            "Peak VRAM during loading: 15.684 GiB\n",
            "  0%|                                                   | 0/200 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
            "{'loss': 3.8798, 'grad_norm': 3.334406852722168, 'learning_rate': 0.0001, 'epoch': 0.01}\n",
            "{'loss': 3.7007, 'grad_norm': 3.0189285278320312, 'learning_rate': 9.95e-05, 'epoch': 0.01}\n",
            "{'loss': 3.1371, 'grad_norm': 2.0998125076293945, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.01}\n",
            "{'loss': 2.8752, 'grad_norm': 2.0570120811462402, 'learning_rate': 9.850000000000001e-05, 'epoch': 0.02}\n",
            "{'loss': 2.4947, 'grad_norm': 2.125084161758423, 'learning_rate': 9.8e-05, 'epoch': 0.03}\n",
            "{'loss': 1.9545, 'grad_norm': 2.277794599533081, 'learning_rate': 9.75e-05, 'epoch': 0.03}\n",
            "{'loss': 1.6076, 'grad_norm': 2.1432201862335205, 'learning_rate': 9.7e-05, 'epoch': 0.04}\n",
            "{'loss': 1.4853, 'grad_norm': 1.8162798881530762, 'learning_rate': 9.65e-05, 'epoch': 0.04}\n",
            "{'loss': 1.3721, 'grad_norm': 1.7210129499435425, 'learning_rate': 9.6e-05, 'epoch': 0.04}\n",
            "{'loss': 1.0993, 'grad_norm': 1.84781813621521, 'learning_rate': 9.55e-05, 'epoch': 0.05}\n",
            "{'loss': 0.9319, 'grad_norm': 2.134505271911621, 'learning_rate': 9.5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.678, 'grad_norm': 2.334911346435547, 'learning_rate': 9.449999999999999e-05, 'epoch': 0.06}\n",
            "{'loss': 0.6866, 'grad_norm': 1.1990097761154175, 'learning_rate': 9.4e-05, 'epoch': 0.07}\n",
            "{'loss': 0.4714, 'grad_norm': 1.0405148267745972, 'learning_rate': 9.350000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.4126, 'grad_norm': 1.2269374132156372, 'learning_rate': 9.300000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 0.4801, 'grad_norm': 1.4728714227676392, 'learning_rate': 9.250000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 0.5339, 'grad_norm': 1.308302879333496, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3963, 'grad_norm': 0.9551699161529541, 'learning_rate': 9.15e-05, 'epoch': 0.09}\n",
            "{'loss': 0.3934, 'grad_norm': 0.9096381068229675, 'learning_rate': 9.1e-05, 'epoch': 0.1}\n",
            "{'loss': 0.3532, 'grad_norm': 0.9253289103507996, 'learning_rate': 9.05e-05, 'epoch': 0.1}\n",
            "{'loss': 0.4868, 'grad_norm': 1.690185546875, 'learning_rate': 9e-05, 'epoch': 0.1}\n",
            "{'loss': 0.3146, 'grad_norm': 1.0684521198272705, 'learning_rate': 8.950000000000001e-05, 'epoch': 0.11}\n",
            "{'loss': 0.4155, 'grad_norm': 1.5345704555511475, 'learning_rate': 8.900000000000001e-05, 'epoch': 0.12}\n",
            "{'loss': 0.371, 'grad_norm': 0.8562999367713928, 'learning_rate': 8.850000000000001e-05, 'epoch': 0.12}\n",
            "{'loss': 0.3455, 'grad_norm': 1.079615831375122, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.12}\n",
            "{'loss': 0.3049, 'grad_norm': 1.5899572372436523, 'learning_rate': 8.75e-05, 'epoch': 0.13}\n",
            "{'loss': 0.3495, 'grad_norm': 1.3648301362991333, 'learning_rate': 8.7e-05, 'epoch': 0.14}\n",
            "{'loss': 0.2487, 'grad_norm': 1.1046301126480103, 'learning_rate': 8.65e-05, 'epoch': 0.14}\n",
            "{'loss': 0.3425, 'grad_norm': 1.1864374876022339, 'learning_rate': 8.6e-05, 'epoch': 0.14}\n",
            "{'loss': 0.2125, 'grad_norm': 0.9726386070251465, 'learning_rate': 8.55e-05, 'epoch': 0.15}\n",
            "{'loss': 0.3309, 'grad_norm': 1.206363558769226, 'learning_rate': 8.5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.2514, 'grad_norm': 1.0993973016738892, 'learning_rate': 8.450000000000001e-05, 'epoch': 0.16}\n",
            "{'loss': 0.2155, 'grad_norm': 1.4713809490203857, 'learning_rate': 8.4e-05, 'epoch': 0.17}\n",
            "{'loss': 0.3439, 'grad_norm': 1.0992863178253174, 'learning_rate': 8.35e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2614, 'grad_norm': 0.9816807508468628, 'learning_rate': 8.3e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2161, 'grad_norm': 2.0218446254730225, 'learning_rate': 8.25e-05, 'epoch': 0.18}\n",
            "{'loss': 0.4216, 'grad_norm': 1.4452202320098877, 'learning_rate': 8.2e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2471, 'grad_norm': 1.6823220252990723, 'learning_rate': 8.15e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2525, 'grad_norm': 1.3903883695602417, 'learning_rate': 8.1e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2837, 'grad_norm': 1.232328176498413, 'learning_rate': 8.05e-05, 'epoch': 0.2}\n",
            "{'loss': 0.4673, 'grad_norm': 2.012444257736206, 'learning_rate': 8e-05, 'epoch': 0.2}\n",
            "{'loss': 0.421, 'grad_norm': 2.479142665863037, 'learning_rate': 7.950000000000001e-05, 'epoch': 0.21}\n",
            "{'loss': 0.243, 'grad_norm': 1.8292927742004395, 'learning_rate': 7.900000000000001e-05, 'epoch': 0.21}\n",
            "{'loss': 0.1729, 'grad_norm': 0.7862820625305176, 'learning_rate': 7.850000000000001e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2019, 'grad_norm': 1.4674381017684937, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.23}\n",
            "{'loss': 0.264, 'grad_norm': 2.009735584259033, 'learning_rate': 7.75e-05, 'epoch': 0.23}\n",
            "{'loss': 0.2661, 'grad_norm': 1.8810828924179077, 'learning_rate': 7.7e-05, 'epoch': 0.23}\n",
            "{'loss': 0.1547, 'grad_norm': 1.0816619396209717, 'learning_rate': 7.65e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2703, 'grad_norm': 2.047701120376587, 'learning_rate': 7.6e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2416, 'grad_norm': 2.3677892684936523, 'learning_rate': 7.55e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2493, 'grad_norm': 1.6438122987747192, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.26}\n",
            "{'loss': 0.1578, 'grad_norm': 1.1536588668823242, 'learning_rate': 7.450000000000001e-05, 'epoch': 0.26}\n",
            "{'loss': 0.1871, 'grad_norm': 0.8910617828369141, 'learning_rate': 7.4e-05, 'epoch': 0.27}\n",
            "{'loss': 0.1715, 'grad_norm': 1.0076255798339844, 'learning_rate': 7.35e-05, 'epoch': 0.27}\n",
            "{'loss': 0.1702, 'grad_norm': 1.1435142755508423, 'learning_rate': 7.3e-05, 'epoch': 0.28}\n",
            "{'loss': 0.1481, 'grad_norm': 1.201672077178955, 'learning_rate': 7.25e-05, 'epoch': 0.28}\n",
            "{'loss': 0.1897, 'grad_norm': 1.0245068073272705, 'learning_rate': 7.2e-05, 'epoch': 0.28}\n",
            "{'loss': 0.1931, 'grad_norm': 1.0743869543075562, 'learning_rate': 7.15e-05, 'epoch': 0.29}\n",
            "{'loss': 0.1106, 'grad_norm': 1.427591323852539, 'learning_rate': 7.1e-05, 'epoch': 0.29}\n",
            "{'loss': 0.1381, 'grad_norm': 0.8052223324775696, 'learning_rate': 7.05e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0993, 'grad_norm': 0.8418385982513428, 'learning_rate': 7e-05, 'epoch': 0.3}\n",
            "{'loss': 0.1524, 'grad_norm': 1.3558969497680664, 'learning_rate': 6.95e-05, 'epoch': 0.31}\n",
            "{'loss': 0.1032, 'grad_norm': 0.8331834673881531, 'learning_rate': 6.9e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0543, 'grad_norm': 0.820562481880188, 'learning_rate': 6.850000000000001e-05, 'epoch': 0.32}\n",
            "{'loss': 0.1716, 'grad_norm': 1.8927096128463745, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.33}\n",
            "{'loss': 0.2024, 'grad_norm': 2.556110382080078, 'learning_rate': 6.750000000000001e-05, 'epoch': 0.33}\n",
            "{'loss': 0.1011, 'grad_norm': 3.7473371028900146, 'learning_rate': 6.7e-05, 'epoch': 0.34}\n",
            "{'loss': 0.1156, 'grad_norm': 1.485397219657898, 'learning_rate': 6.65e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0931, 'grad_norm': 1.4301468133926392, 'learning_rate': 6.6e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0505, 'grad_norm': 0.7474769353866577, 'learning_rate': 6.55e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0333, 'grad_norm': 1.06316077709198, 'learning_rate': 6.500000000000001e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0649, 'grad_norm': 1.397025227546692, 'learning_rate': 6.450000000000001e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0927, 'grad_norm': 1.6019331216812134, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0234, 'grad_norm': 0.7478642463684082, 'learning_rate': 6.35e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0209, 'grad_norm': 0.6037619113922119, 'learning_rate': 6.3e-05, 'epoch': 0.38}\n",
            "{'loss': 0.1019, 'grad_norm': 2.169459104537964, 'learning_rate': 6.25e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0474, 'grad_norm': 1.2902485132217407, 'learning_rate': 6.2e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0231, 'grad_norm': 0.5678645372390747, 'learning_rate': 6.15e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0679, 'grad_norm': 1.8793202638626099, 'learning_rate': 6.1e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0289, 'grad_norm': 0.7341600656509399, 'learning_rate': 6.05e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0555, 'grad_norm': 1.8916467428207397, 'learning_rate': 6e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0167, 'grad_norm': 0.73353511095047, 'learning_rate': 5.95e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0288, 'grad_norm': 1.3401167392730713, 'learning_rate': 5.9e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0354, 'grad_norm': 0.5723248720169067, 'learning_rate': 5.85e-05, 'epoch': 0.42}\n",
            "{'loss': 0.2513, 'grad_norm': 3.9552485942840576, 'learning_rate': 5.8e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0257, 'grad_norm': 1.0954844951629639, 'learning_rate': 5.7499999999999995e-05, 'epoch': 0.43}\n",
            "{'loss': 0.046, 'grad_norm': 0.6912179589271545, 'learning_rate': 5.6999999999999996e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0142, 'grad_norm': 0.6350668668746948, 'learning_rate': 5.65e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0081, 'grad_norm': 1.4568181037902832, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0312, 'grad_norm': 0.6619327664375305, 'learning_rate': 5.550000000000001e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0746, 'grad_norm': 1.4146232604980469, 'learning_rate': 5.500000000000001e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0039, 'grad_norm': 0.32026299834251404, 'learning_rate': 5.45e-05, 'epoch': 0.46}\n",
            "{'loss': 0.037, 'grad_norm': 0.8198896050453186, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0464, 'grad_norm': 0.5820574164390564, 'learning_rate': 5.3500000000000006e-05, 'epoch': 0.47}\n",
            "{'loss': 0.1098, 'grad_norm': 1.0117253065109253, 'learning_rate': 5.300000000000001e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0033, 'grad_norm': 0.13891711831092834, 'learning_rate': 5.25e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0469, 'grad_norm': 0.7273072004318237, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0154, 'grad_norm': 2.2206616401672363, 'learning_rate': 5.1500000000000005e-05, 'epoch': 0.49}\n",
            "{'loss': 0.1095, 'grad_norm': 2.5771121978759766, 'learning_rate': 5.1000000000000006e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0226, 'grad_norm': 0.47204798460006714, 'learning_rate': 5.05e-05, 'epoch': 0.5}\n",
            " 50%|████████████████████▌                    | 100/200 [00:54<00:54,  1.82it/s]\n",
            "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|█▊                                          | 2/50 [00:00<00:06,  7.37it/s]\u001b[A\n",
            "  6%|██▋                                         | 3/50 [00:00<00:09,  5.18it/s]\u001b[A\n",
            "  8%|███▌                                        | 4/50 [00:00<00:10,  4.50it/s]\u001b[A\n",
            " 10%|████▍                                       | 5/50 [00:01<00:10,  4.19it/s]\u001b[A\n",
            " 12%|█████▎                                      | 6/50 [00:01<00:10,  4.01it/s]\u001b[A\n",
            " 14%|██████▏                                     | 7/50 [00:01<00:11,  3.91it/s]\u001b[A\n",
            " 16%|███████                                     | 8/50 [00:01<00:10,  3.84it/s]\u001b[A\n",
            " 18%|███████▉                                    | 9/50 [00:02<00:10,  3.80it/s]\u001b[A\n",
            " 20%|████████▌                                  | 10/50 [00:02<00:10,  3.75it/s]\u001b[A\n",
            " 22%|█████████▍                                 | 11/50 [00:02<00:10,  3.75it/s]\u001b[A\n",
            " 24%|██████████▎                                | 12/50 [00:02<00:10,  3.67it/s]\u001b[A\n",
            " 26%|███████████▏                               | 13/50 [00:03<00:10,  3.67it/s]\u001b[A\n",
            " 28%|████████████                               | 14/50 [00:03<00:10,  3.54it/s]\u001b[A\n",
            " 30%|████████████▉                              | 15/50 [00:03<00:09,  3.58it/s]\u001b[A\n",
            " 32%|█████████████▊                             | 16/50 [00:04<00:09,  3.58it/s]\u001b[A\n",
            " 34%|██████████████▌                            | 17/50 [00:04<00:09,  3.61it/s]\u001b[A\n",
            " 36%|███████████████▍                           | 18/50 [00:04<00:08,  3.58it/s]\u001b[A\n",
            " 38%|████████████████▎                          | 19/50 [00:04<00:08,  3.61it/s]\u001b[A\n",
            " 40%|█████████████████▏                         | 20/50 [00:05<00:08,  3.64it/s]\u001b[A\n",
            " 42%|██████████████████                         | 21/50 [00:05<00:07,  3.64it/s]\u001b[A\n",
            " 44%|██████████████████▉                        | 22/50 [00:05<00:07,  3.65it/s]\u001b[A\n",
            " 46%|███████████████████▊                       | 23/50 [00:06<00:07,  3.65it/s]\u001b[A\n",
            " 48%|████████████████████▋                      | 24/50 [00:06<00:07,  3.66it/s]\u001b[A\n",
            " 50%|█████████████████████▌                     | 25/50 [00:06<00:06,  3.68it/s]\u001b[A\n",
            " 52%|██████████████████████▎                    | 26/50 [00:06<00:06,  3.68it/s]\u001b[A\n",
            " 54%|███████████████████████▏                   | 27/50 [00:07<00:06,  3.65it/s]\u001b[A\n",
            " 56%|████████████████████████                   | 28/50 [00:07<00:06,  3.64it/s]\u001b[A\n",
            " 58%|████████████████████████▉                  | 29/50 [00:07<00:05,  3.63it/s]\u001b[A\n",
            " 60%|█████████████████████████▊                 | 30/50 [00:07<00:05,  3.63it/s]\u001b[A\n",
            " 62%|██████████████████████████▋                | 31/50 [00:08<00:05,  3.61it/s]\u001b[A\n",
            " 64%|███████████████████████████▌               | 32/50 [00:08<00:04,  3.63it/s]\u001b[A\n",
            " 66%|████████████████████████████▍              | 33/50 [00:08<00:04,  3.65it/s]\u001b[A\n",
            " 68%|█████████████████████████████▏             | 34/50 [00:09<00:04,  3.60it/s]\u001b[A\n",
            " 70%|██████████████████████████████             | 35/50 [00:09<00:04,  3.63it/s]\u001b[A\n",
            " 72%|██████████████████████████████▉            | 36/50 [00:09<00:03,  3.62it/s]\u001b[A\n",
            " 74%|███████████████████████████████▊           | 37/50 [00:09<00:03,  3.65it/s]\u001b[A\n",
            " 76%|████████████████████████████████▋          | 38/50 [00:10<00:03,  3.65it/s]\u001b[A\n",
            " 78%|█████████████████████████████████▌         | 39/50 [00:10<00:03,  3.65it/s]\u001b[A\n",
            " 80%|██████████████████████████████████▍        | 40/50 [00:10<00:02,  3.65it/s]\u001b[A\n",
            " 82%|███████████████████████████████████▎       | 41/50 [00:10<00:02,  3.67it/s]\u001b[A\n",
            " 84%|████████████████████████████████████       | 42/50 [00:11<00:02,  3.68it/s]\u001b[A\n",
            " 86%|████████████████████████████████████▉      | 43/50 [00:11<00:01,  3.68it/s]\u001b[A\n",
            " 88%|█████████████████████████████████████▊     | 44/50 [00:11<00:01,  3.69it/s]\u001b[A\n",
            " 90%|██████████████████████████████████████▋    | 45/50 [00:12<00:01,  3.70it/s]\u001b[A\n",
            " 92%|███████████████████████████████████████▌   | 46/50 [00:12<00:01,  3.70it/s]\u001b[A\n",
            " 94%|████████████████████████████████████████▍  | 47/50 [00:12<00:00,  3.67it/s]\u001b[A\n",
            " 96%|█████████████████████████████████████████▎ | 48/50 [00:12<00:00,  3.67it/s]\u001b[A\n",
            "                                                                                \n",
            "\u001b[A{'eval_loss': 0.024724585935473442, 'eval_runtime': 13.7345, 'eval_samples_per_second': 29.124, 'eval_steps_per_second': 3.64, 'epoch': 0.5}\n",
            " 50%|████████████████████▌                    | 100/200 [01:08<00:54,  1.82it/s]\n",
            "100%|███████████████████████████████████████████| 50/50 [00:13<00:00,  3.64it/s]\u001b[A\n",
            "{'loss': 0.0104, 'grad_norm': 0.27441102266311646, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0259, 'grad_norm': 0.5289071798324585, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0065, 'grad_norm': 0.1979151964187622, 'learning_rate': 4.9e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0454, 'grad_norm': 0.7076249122619629, 'learning_rate': 4.85e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0155, 'grad_norm': 0.2632577419281006, 'learning_rate': 4.8e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0028, 'grad_norm': 0.09145134687423706, 'learning_rate': 4.75e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0046, 'grad_norm': 0.1635063886642456, 'learning_rate': 4.7e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0272, 'grad_norm': 0.48351213335990906, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.54}\n",
            "{'loss': 0.013, 'grad_norm': 0.3370397090911865, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0091, 'grad_norm': 0.39271774888038635, 'learning_rate': 4.55e-05, 'epoch': 0.55}\n",
            "{'loss': 0.029, 'grad_norm': 0.373055100440979, 'learning_rate': 4.5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0042, 'grad_norm': 0.10093499720096588, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0106, 'grad_norm': 0.2698180079460144, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0066, 'grad_norm': 0.19990034401416779, 'learning_rate': 4.35e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0052, 'grad_norm': 0.1566479355096817, 'learning_rate': 4.3e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0334, 'grad_norm': 0.5011986494064331, 'learning_rate': 4.25e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0059, 'grad_norm': 0.19197455048561096, 'learning_rate': 4.2e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0183, 'grad_norm': 0.34592995047569275, 'learning_rate': 4.15e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0209, 'grad_norm': 0.5290577411651611, 'learning_rate': 4.1e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0086, 'grad_norm': 1.0749608278274536, 'learning_rate': 4.05e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0164, 'grad_norm': 0.3299790620803833, 'learning_rate': 4e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0027, 'grad_norm': 0.07029711455106735, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0196, 'grad_norm': 0.5239251852035522, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0021, 'grad_norm': 0.07464191317558289, 'learning_rate': 3.85e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0083, 'grad_norm': 0.18817107379436493, 'learning_rate': 3.8e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0142, 'grad_norm': 0.34566447138786316, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0058, 'grad_norm': 0.20721867680549622, 'learning_rate': 3.7e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0013, 'grad_norm': 0.04172162711620331, 'learning_rate': 3.65e-05, 'epoch': 0.64}\n",
            "{'loss': 0.031, 'grad_norm': 0.42425182461738586, 'learning_rate': 3.6e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0024, 'grad_norm': 0.10855445265769958, 'learning_rate': 3.55e-05, 'epoch': 0.65}\n",
            "{'loss': 0.045, 'grad_norm': 0.5043087005615234, 'learning_rate': 3.5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0041, 'grad_norm': 0.16224557161331177, 'learning_rate': 3.45e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0006, 'grad_norm': 0.016871673986315727, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0169, 'grad_norm': 0.7481115460395813, 'learning_rate': 3.35e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0014, 'grad_norm': 0.03646358847618103, 'learning_rate': 3.3e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0418, 'grad_norm': 0.7715514898300171, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0012, 'grad_norm': 0.03964179381728172, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0019, 'grad_norm': 0.06239127367734909, 'learning_rate': 3.15e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0024, 'grad_norm': 0.07099512219429016, 'learning_rate': 3.1e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0015, 'grad_norm': 0.04776877909898758, 'learning_rate': 3.05e-05, 'epoch': 0.7}\n",
            "{'loss': 0.003, 'grad_norm': 0.11723734438419342, 'learning_rate': 3e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0162, 'grad_norm': 0.42396748065948486, 'learning_rate': 2.95e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0164, 'grad_norm': 0.5086605548858643, 'learning_rate': 2.9e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0029, 'grad_norm': 0.1378346085548401, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0298, 'grad_norm': 0.5666443705558777, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0005, 'grad_norm': 0.02786422334611416, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.73}\n",
            "{'loss': 0.008, 'grad_norm': 0.30056095123291016, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0153, 'grad_norm': 0.3751290440559387, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0061, 'grad_norm': 0.2645200192928314, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0008, 'grad_norm': 0.02169119194149971, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0018, 'grad_norm': 0.1015157625079155, 'learning_rate': 2.5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0014, 'grad_norm': 0.06002773717045784, 'learning_rate': 2.45e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0164, 'grad_norm': 0.5490373969078064, 'learning_rate': 2.4e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0029, 'grad_norm': 0.10975899547338486, 'learning_rate': 2.35e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0144, 'grad_norm': 0.4536389112472534, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.78}\n",
            "{'loss': 0.002, 'grad_norm': 0.07598119229078293, 'learning_rate': 2.25e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0033, 'grad_norm': 0.2406967282295227, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0017, 'grad_norm': 0.1115550547838211, 'learning_rate': 2.15e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0011, 'grad_norm': 0.03353866934776306, 'learning_rate': 2.1e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0005, 'grad_norm': 0.0164929386228323, 'learning_rate': 2.05e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0061, 'grad_norm': 0.22164742648601532, 'learning_rate': 2e-05, 'epoch': 0.81}\n",
            "{'loss': 0.108, 'grad_norm': 0.8932308554649353, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0004, 'grad_norm': 0.010719215497374535, 'learning_rate': 1.9e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0255, 'grad_norm': 0.6747885346412659, 'learning_rate': 1.85e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0239, 'grad_norm': 0.5241852402687073, 'learning_rate': 1.8e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0022, 'grad_norm': 0.16037701070308685, 'learning_rate': 1.75e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0155, 'grad_norm': 0.4784352779388428, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0028, 'grad_norm': 0.1255672723054886, 'learning_rate': 1.65e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0199, 'grad_norm': 0.4641548693180084, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0014, 'grad_norm': 0.07316508144140244, 'learning_rate': 1.55e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0722, 'grad_norm': 0.9278074502944946, 'learning_rate': 1.5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0024, 'grad_norm': 0.11668077856302261, 'learning_rate': 1.45e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0004, 'grad_norm': 0.011865249834954739, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0149, 'grad_norm': 0.6439648866653442, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0007, 'grad_norm': 0.018222223967313766, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0029, 'grad_norm': 0.09686902165412903, 'learning_rate': 1.25e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0008, 'grad_norm': 0.046028021723032, 'learning_rate': 1.2e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0004, 'grad_norm': 0.013339672237634659, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0005, 'grad_norm': 0.020226595923304558, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0009, 'grad_norm': 0.033308885991573334, 'learning_rate': 1.05e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0031, 'grad_norm': 0.09159128367900848, 'learning_rate': 1e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0082, 'grad_norm': 0.3722434937953949, 'learning_rate': 9.5e-06, 'epoch': 0.91}\n",
            "{'loss': 0.0153, 'grad_norm': 0.37921142578125, 'learning_rate': 9e-06, 'epoch': 0.92}\n",
            "{'loss': 0.0196, 'grad_norm': 0.5568834543228149, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.92}\n",
            "{'loss': 0.006, 'grad_norm': 0.3224295675754547, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.93}\n",
            "{'loss': 0.0173, 'grad_norm': 0.5628081560134888, 'learning_rate': 7.5e-06, 'epoch': 0.93}\n",
            "{'loss': 0.0007, 'grad_norm': 0.021828550845384598, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.94}\n",
            "{'loss': 0.004, 'grad_norm': 0.15872536599636078, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.94}\n",
            "{'loss': 0.0014, 'grad_norm': 0.06511203199625015, 'learning_rate': 6e-06, 'epoch': 0.94}\n",
            "{'loss': 0.0473, 'grad_norm': 1.0012849569320679, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.95}\n",
            "{'loss': 0.0029, 'grad_norm': 0.08493993431329727, 'learning_rate': 5e-06, 'epoch': 0.95}\n",
            "{'loss': 0.0135, 'grad_norm': 0.4588845372200012, 'learning_rate': 4.5e-06, 'epoch': 0.96}\n",
            "{'loss': 0.025, 'grad_norm': 0.7216715812683105, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.96}\n",
            "{'loss': 0.0017, 'grad_norm': 0.0667814165353775, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.97}\n",
            "{'loss': 0.0003, 'grad_norm': 0.008921091444790363, 'learning_rate': 3e-06, 'epoch': 0.97}\n",
            "{'loss': 0.0038, 'grad_norm': 0.16434438526630402, 'learning_rate': 2.5e-06, 'epoch': 0.98}\n",
            "{'loss': 0.0067, 'grad_norm': 0.3127196431159973, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.98}\n",
            "{'loss': 0.0024, 'grad_norm': 0.11816935986280441, 'learning_rate': 1.5e-06, 'epoch': 0.99}\n",
            "{'loss': 0.0142, 'grad_norm': 0.3902797996997833, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.99}\n",
            "{'loss': 0.004, 'grad_norm': 0.18337391316890717, 'learning_rate': 5.000000000000001e-07, 'epoch': 1.0}\n",
            "100%|█████████████████████████████████████████| 200/200 [02:01<00:00,  2.19it/s]\n",
            "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|█▊                                          | 2/50 [00:00<00:06,  7.44it/s]\u001b[A\n",
            "  6%|██▋                                         | 3/50 [00:00<00:08,  5.23it/s]\u001b[A\n",
            "  8%|███▌                                        | 4/50 [00:00<00:10,  4.52it/s]\u001b[A\n",
            " 10%|████▍                                       | 5/50 [00:01<00:10,  4.18it/s]\u001b[A\n",
            " 12%|█████▎                                      | 6/50 [00:01<00:10,  4.01it/s]\u001b[A\n",
            " 14%|██████▏                                     | 7/50 [00:01<00:10,  3.91it/s]\u001b[A\n",
            " 16%|███████                                     | 8/50 [00:01<00:10,  3.84it/s]\u001b[A\n",
            " 18%|███████▉                                    | 9/50 [00:02<00:10,  3.77it/s]\u001b[A\n",
            " 20%|████████▌                                  | 10/50 [00:02<00:10,  3.75it/s]\u001b[A\n",
            " 22%|█████████▍                                 | 11/50 [00:02<00:10,  3.72it/s]\u001b[A\n",
            " 24%|██████████▎                                | 12/50 [00:02<00:10,  3.72it/s]\u001b[A\n",
            " 26%|███████████▏                               | 13/50 [00:03<00:09,  3.71it/s]\u001b[A\n",
            " 28%|████████████                               | 14/50 [00:03<00:09,  3.70it/s]\u001b[A\n",
            " 30%|████████████▉                              | 15/50 [00:03<00:09,  3.70it/s]\u001b[A\n",
            " 32%|█████████████▊                             | 16/50 [00:04<00:09,  3.70it/s]\u001b[A\n",
            " 34%|██████████████▌                            | 17/50 [00:04<00:08,  3.71it/s]\u001b[A\n",
            " 36%|███████████████▍                           | 18/50 [00:04<00:08,  3.70it/s]\u001b[A\n",
            " 38%|████████████████▎                          | 19/50 [00:04<00:08,  3.70it/s]\u001b[A\n",
            " 40%|█████████████████▏                         | 20/50 [00:05<00:08,  3.71it/s]\u001b[A\n",
            " 42%|██████████████████                         | 21/50 [00:05<00:07,  3.71it/s]\u001b[A\n",
            " 44%|██████████████████▉                        | 22/50 [00:05<00:07,  3.71it/s]\u001b[A\n",
            " 46%|███████████████████▊                       | 23/50 [00:05<00:07,  3.71it/s]\u001b[A\n",
            " 48%|████████████████████▋                      | 24/50 [00:06<00:06,  3.72it/s]\u001b[A\n",
            " 50%|█████████████████████▌                     | 25/50 [00:06<00:06,  3.71it/s]\u001b[A\n",
            " 52%|██████████████████████▎                    | 26/50 [00:06<00:06,  3.64it/s]\u001b[A\n",
            " 54%|███████████████████████▏                   | 27/50 [00:07<00:06,  3.65it/s]\u001b[A\n",
            " 56%|████████████████████████                   | 28/50 [00:07<00:05,  3.67it/s]\u001b[A\n",
            " 58%|████████████████████████▉                  | 29/50 [00:07<00:05,  3.67it/s]\u001b[A\n",
            " 60%|█████████████████████████▊                 | 30/50 [00:07<00:05,  3.67it/s]\u001b[A\n",
            " 62%|██████████████████████████▋                | 31/50 [00:08<00:05,  3.68it/s]\u001b[A\n",
            " 64%|███████████████████████████▌               | 32/50 [00:08<00:04,  3.69it/s]\u001b[A\n",
            " 66%|████████████████████████████▍              | 33/50 [00:08<00:04,  3.69it/s]\u001b[A\n",
            " 68%|█████████████████████████████▏             | 34/50 [00:08<00:04,  3.65it/s]\u001b[A\n",
            " 70%|██████████████████████████████             | 35/50 [00:09<00:04,  3.63it/s]\u001b[A\n",
            " 72%|██████████████████████████████▉            | 36/50 [00:09<00:03,  3.64it/s]\u001b[A\n",
            " 74%|███████████████████████████████▊           | 37/50 [00:09<00:03,  3.65it/s]\u001b[A\n",
            " 76%|████████████████████████████████▋          | 38/50 [00:10<00:03,  3.67it/s]\u001b[A\n",
            " 78%|█████████████████████████████████▌         | 39/50 [00:10<00:03,  3.66it/s]\u001b[A\n",
            " 80%|██████████████████████████████████▍        | 40/50 [00:10<00:02,  3.67it/s]\u001b[A\n",
            " 82%|███████████████████████████████████▎       | 41/50 [00:10<00:02,  3.68it/s]\u001b[A\n",
            " 84%|████████████████████████████████████       | 42/50 [00:11<00:02,  3.69it/s]\u001b[A\n",
            " 86%|████████████████████████████████████▉      | 43/50 [00:11<00:01,  3.68it/s]\u001b[A\n",
            " 88%|█████████████████████████████████████▊     | 44/50 [00:11<00:01,  3.68it/s]\u001b[A\n",
            " 90%|██████████████████████████████████████▋    | 45/50 [00:11<00:01,  3.66it/s]\u001b[A\n",
            " 92%|███████████████████████████████████████▌   | 46/50 [00:12<00:01,  3.65it/s]\u001b[A\n",
            " 94%|████████████████████████████████████████▍  | 47/50 [00:12<00:00,  3.67it/s]\u001b[A\n",
            " 96%|█████████████████████████████████████████▎ | 48/50 [00:12<00:00,  3.66it/s]\u001b[A\n",
            "                                                                                \n",
            "\u001b[A{'eval_loss': 0.01489165797829628, 'eval_runtime': 13.6098, 'eval_samples_per_second': 29.391, 'eval_steps_per_second': 3.674, 'epoch': 1.0}\n",
            "100%|█████████████████████████████████████████| 200/200 [02:15<00:00,  2.19it/s]\n",
            "100%|███████████████████████████████████████████| 50/50 [00:13<00:00,  3.66it/s]\u001b[A\n",
            "{'train_runtime': 137.5791, 'train_samples_per_second': 11.63, 'train_steps_per_second': 1.454, 'train_loss': 0.21687773093944998, 'epoch': 1.0}\n",
            "100%|█████████████████████████████████████████| 200/200 [02:17<00:00,  1.45it/s]\n",
            "TrainOutput(global_step=200, training_loss=0.21687773093944998, metrics={'train_runtime': 137.5791, 'train_samples_per_second': 11.63, 'train_steps_per_second': 1.454, 'total_flos': 5646339091599360.0, 'train_loss': 0.21687773093944998, 'epoch': 1.0})\n",
            "Peak VRAM during training: 17.510 GiB\n"
          ]
        }
      ],
      "source": [
        "!mdl-toolkit train \\\n",
        "     --lora-rank 32 \\\n",
        "     --eval-steps 100 \\\n",
        "     --train-dataset train-converted/ \\\n",
        "     --eval-dataset test-converted/ \\\n",
        "     --output output/ \\\n",
        "     --model-name mispeech/midashenglm-7b-bf16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e33BJPrBHa5N"
      },
      "source": [
        "## 进行推理\n",
        "\n",
        "训练完成后，我们可以使用训练好的模型进行推理。训练结果默认已经合并了 LoRA 适配器，其推理方式与基础模型相同，仅需指定模型路径，即可使用原始模型的推理代码进行推理："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiAIrMtWHa5N",
        "outputId": "42181de7-9e1f-411a-c381-8e0e2cc34180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/h30/zhoujiahao5/notebook/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['category: pig, target: 2']\n"
          ]
        }
      ],
      "source": [
        "# 在 Notebook 中设置 TOKENIZERS_PARALLELISM=0 以防止警告干扰输出\n",
        "# 不要在 Notebook 之外设置，否则可能导致性能降低\n",
        "import os\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\"\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor, AutoTokenizer\n",
        "\n",
        "model_id = \"./output/final/\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"Output the predicted category in the format of category: <category>, category_id: <category_id>.\"},\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"audio\", \"path\": \"ESC-50-master/audio/5-103415-A-2.wav\"},\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "with torch.no_grad():\n",
        "    model_inputs = processor.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        add_special_tokens=True,\n",
        "        return_dict=True,\n",
        "    ).to(device=model.device, dtype=model.dtype)\n",
        "    generation = model.generate(**model_inputs)\n",
        "    output = tokenizer.batch_decode(generation, skip_special_tokens=True)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OyfJdszHa5N"
      },
      "source": [
        "我们也可以使用 MDL-Toolkit 的推理命令获取推理结果："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEHBYrH3Ha5N",
        "outputId": "7f02c87e-96fc-4ad7-dde6-3a8754ec433b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:04<00:00,  1.12s/it]\n",
            "Processing dataset: 100%|██████████████| 400/400 [00:10<00:00, 37.31 examples/s]\n",
            "Batching examples (num_proc=32): 100%|█| 400/400 [00:02<00:00, 147.34 examples/s\n",
            "Inference: 100%|████████████████████████████████| 32/32 [00:33<00:00,  1.06s/it]\n"
          ]
        }
      ],
      "source": [
        "!mdl-toolkit inference \\\n",
        "    test.csv \\\n",
        "    --system-prompt \"You are a helpful audio classifier.\" \\\n",
        "    --user-prompt \"Output the predicted category in the format of category: <category>, category_id: <category_id>.\" \\\n",
        "    --output finetuned-output.csv \\\n",
        "    --model-name ./output/final/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrVClf7EHa5O"
      },
      "source": [
        "推理结果将保存在指定的输出 CSV 文件中，输出文件的格式与训练时使用的格式相同。经过微调后，模型应该能够使用训练时指定的格式生成输出："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zQKD5j8Ha5O",
        "outputId": "9371dd1d-1168-4f19-bc5f-7011c7152c0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio,prediction\r\r\n",
            "ESC-50-master/audio/5-103415-A-2.wav,\"category: livestock, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-103416-A-2.wav,\"category: music, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-103418-A-2.wav,\"category: pig, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-103420-A-2.wav,\"category: animal, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-103421-A-2.wav,\"category: pig, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-103422-A-2.wav,\"category: animal, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-117118-A-42.wav,\"category: alarm, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-117120-A-42.wav,\"category: alarm, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-117122-A-42.wav,\"category: alarm, category_id: 1\"\r\r\n",
            "ESC-50-master/audio/5-117250-A-2.wav,\"category: animal, category_id: 1\"\n",
            "audio,prediction\n",
            "ESC-50-master/audio/5-103415-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103416-A-2.wav,\"category: door_wood_creaks, target: 33\"\n",
            "ESC-50-master/audio/5-103418-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103420-A-2.wav,\"category: rooster, target: 1\"\n",
            "ESC-50-master/audio/5-103421-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-103422-A-2.wav,\"category: pig, target: 2\"\n",
            "ESC-50-master/audio/5-117118-A-42.wav,\"category: siren, target: 42\"\n",
            "ESC-50-master/audio/5-117120-A-42.wav,\"category: siren, target: 42\"\n",
            "ESC-50-master/audio/5-117122-A-42.wav,\"category: siren, target: 42\"\n",
            "ESC-50-master/audio/5-117250-A-2.wav,\"category: snoring, target: 28\"\n"
          ]
        }
      ],
      "source": [
        "! head -n 11 orig-output.csv\n",
        "! head -n 11 finetuned-output.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 如何提高性能\n",
        "\n",
        "恭喜你完成了模型的第一次微调！但是，在不同任务数据上，本教程提供的超参数可能不能达到你心目中理想的效果。如果你对微调结果不满意，可以尝试以下方法：\n",
        "\n",
        "1. 提高 LoRA Rank，例如使用`--lora-rank 64`。\n",
        "2. 调整学习率，例如使用`--lr 5e-5`。最佳学习率受到多方面因素影响，可能需要多次尝试或进行系统性超参数搜索才能确定。\n",
        "3. 调整可训练目标，例如使用`--train-target encoder--train-target projector --train-target decoder --train-target embed_tokens --train-target lm_head`以训练所有可训练目标。在某些情况下，增加可训练目标，特别是`embed_tokens`和`lm_head`，可以改进训练结果。\n",
        "4. 提高模型精度。如果使用了量化，则应该尝试在没有量化的情况下运行。如果未使用量化，可以使用`--bf16 false`以将模型加载为 fp32 精度。\n",
        "5. 增加可用训练数据的数量和质量，这可能会改进模型的性能。但重复使用数据，例如将`--num-epochs`设置为大于1的数值，可能效果有限，甚至对性能有负面影响。"
      ],
      "metadata": {
        "id": "vU4pwn2jZWmB"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}